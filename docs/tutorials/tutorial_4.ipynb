{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGa0_oLb61zz"
      },
      "source": [
        "# Tutorial 4\n",
        "In this tutorial, we are going to directly train the weights and delays of a simple SNN with a single hidden layer using EventProp on the Yin-Yang dataset.\n",
        "\n",
        "Clearly, this is far from a state of the art architecture, but it still achieves 96% accuracy on MNIST.\n",
        "\n",
        "## Install\n",
        "Download wheel file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2ihZLXh5VD-",
        "outputId": "b89cfb36-cb83-4b58-cb31-56f9e38ae050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wUeynMCgEOl2oK2LAd4E0s0iT_OiNOfl\n",
            "To: /content/pygenn-5.1.0-cp311-cp311-linux_x86_64.whl\n",
            "\r  0% 0.00/8.49M [00:00<?, ?B/s]\r100% 8.49M/8.49M [00:00<00:00, 76.4MB/s]\r100% 8.49M/8.49M [00:00<00:00, 75.9MB/s]\n",
            "Processing ./pygenn-5.1.0-cp311-cp311-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pygenn==5.1.0) (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from pygenn==5.1.0) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pygenn==5.1.0) (75.2.0)\n",
            "pygenn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "env: CUDA_PATH=/usr/local/cuda\n",
            "--2025-04-24 20:50:04--  https://github.com/genn-team/ml_genn/archive/refs/heads/master.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/genn-team/ml_genn/zip/refs/heads/master [following]\n",
            "--2025-04-24 20:50:04--  https://codeload.github.com/genn-team/ml_genn/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip.4’\n",
            "\n",
            "master.zip.4            [ <=>                ] 680.02K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-24 20:50:04 (14.0 MB/s) - ‘master.zip.4’ saved [696337]\n",
            "\n",
            "Processing ./ml_genn-master/ml_genn\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygenn<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ml_genn==2.3.0) (5.1.0)\n",
            "Requirement already satisfied: enum-compat in /usr/local/lib/python3.11/dist-packages (from ml_genn==2.3.0) (0.0.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from ml_genn==2.3.0) (4.67.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from ml_genn==2.3.0) (1.2.18)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pygenn<6.0.0,>=5.1.0->ml_genn==2.3.0) (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from pygenn<6.0.0,>=5.1.0->ml_genn==2.3.0) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pygenn<6.0.0,>=5.1.0->ml_genn==2.3.0) (75.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->ml_genn==2.3.0) (1.17.2)\n",
            "Building wheels for collected packages: ml_genn\n",
            "  Building wheel for ml_genn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml_genn: filename=ml_genn-2.3.0-py3-none-any.whl size=132273 sha256=249fb5eff948320b958a6757c342c47dbbe007729ea28670c40faa56c6b9289e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qq2tjfa6/wheels/7e/fe/12/587693a91c5d18fe8e77cbb14313ea2ed33e71a9eb3993089f\n",
            "Successfully built ml_genn\n",
            "Installing collected packages: ml_genn\n",
            "  Attempting uninstall: ml_genn\n",
            "    Found existing installation: ml_genn 2.3.0\n",
            "    Uninstalling ml_genn-2.3.0:\n",
            "      Successfully uninstalled ml_genn-2.3.0\n",
            "Successfully installed ml_genn-2.3.0\n"
          ]
        }
      ],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    !gdown 1wUeynMCgEOl2oK2LAd4E0s0iT_OiNOfl\n",
        "    !pip install pygenn-5.1.0-cp311-cp311-linux_x86_64.whl\n",
        "    %env CUDA_PATH=/usr/local/cuda\n",
        "\n",
        "    !rm -rf /content/ml_genn-master\n",
        "    !wget https://github.com/genn-team/ml_genn/archive/refs/heads/master.zip\n",
        "    !unzip -q master.zip\n",
        "    !pip install ./ml_genn-master/ml_genn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwadUz9Azxss"
      },
      "source": [
        "## Build model\n",
        "Import standard modules and required mlGeNN classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "agqWFZjickfU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ml_genn import InputLayer, Layer, SequentialNetwork\n",
        "from ml_genn.callbacks import Checkpoint, OptimiserParamSchedule\n",
        "from ml_genn.compilers import EventPropCompiler, InferenceCompiler\n",
        "from ml_genn.connectivity import Dense\n",
        "from ml_genn.initializers import Normal\n",
        "from ml_genn.neurons import LeakyIntegrate, LeakyIntegrateFire, SpikeInput\n",
        "from ml_genn.optimisers import Adam\n",
        "from ml_genn.serialisers import Numpy\n",
        "from ml_genn.synapses import Exponential\n",
        "\n",
        "from ml_genn.utils.data import generate_yin_yang_dataset\n",
        "\n",
        "from ml_genn.compilers.event_prop_compiler import default_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Parameters\n",
        "\n",
        "Define some model parameters\n"
      ],
      "metadata": {
        "id": "X2hcCpdlzaZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_INPUT = 5\n",
        "NUM_HIDDEN = 30\n",
        "NUM_OUTPUT = 3\n",
        "BATCH_SIZE = 32\n",
        "DT = 0.01\n",
        "NUM_TRAIN = BATCH_SIZE * 10 * NUM_OUTPUT\n",
        "NUM_TEST = BATCH_SIZE  * 2 * NUM_OUTPUT\n",
        "EXAMPLE_TIME = 30.0"
      ],
      "metadata": {
        "id": "x87G22iUzcEU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latency encoding\n",
        "There are numerous ways to encode images using spikes but here we are going to emit a single spike for each neuron at a time proportional the each pixel's grayscale."
      ],
      "metadata": {
        "id": "op6AInYzviqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spikes_train, labels_train = generate_yin_yang_dataset(NUM_TRAIN, EXAMPLE_TIME - (4 * DT), 2 * DT)"
      ],
      "metadata": {
        "id": "2m9780SfvWec"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuwdL6IE2MuS"
      },
      "source": [
        "## Network definition\n",
        "Because our network is entirely feedforward, we can define it as a ``SequentialNetwork`` where each layer is automatically connected to the previous layer. As the yin-yang dataset is already spiking, we will use a ``SpikeInput`` to inject these directly into the network. For our hidden layer we are going to use standard Leaky integrate-and-fire neurons. Finally, we are going to use a spiking output layer and read classifications out of this by determining the time to first spike.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C68EDXn6cj-O"
      },
      "outputs": [],
      "source": [
        "# Create sequential model\n",
        "serialiser = Numpy(\"yin_yang_checkpoints\")\n",
        "network = SequentialNetwork(default_params)\n",
        "with network:\n",
        "    # Populations\n",
        "    input = InputLayer(SpikeInput(max_spikes=BATCH_SIZE * NUM_INPUT),\n",
        "                                  NUM_INPUT)\n",
        "    hidden = Layer(Dense(Normal(mean=1.9, sd=0.78)),\n",
        "                   LeakyIntegrateFire(v_thresh=1.0, tau_mem=20.0,\n",
        "                                      tau_refrac=None),\n",
        "                   NUM_HIDDEN, Exponential(5.0),\n",
        "                   max_delay_steps=1000)\n",
        "    output = Layer(Dense(Normal(mean=0.93, sd=0.1)),\n",
        "                   LeakyIntegrateFire(tau_mem=20.0, readout=\"first_spike_time\"),\n",
        "                   NUM_OUTPUT, Exponential(5.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PCMgNPCz86O"
      },
      "source": [
        "## Compilation\n",
        "In mlGeNN, in order to turn an abstract network description into something that can actually be used for training or inference you use a *compiler* class. Here, we use the ``EventPropCompiler`` to train with EventProp and specify batch size and how many timesteps to evaluate each example for as well as choosing our optimiser and loss function. Because this is a classification task, we want to use cross-entropy loss and, because our labels are specified in this way (rather than e.g. one-hot encoded), we use the sparse catgorical variant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-7lzXzmQcgbt"
      },
      "outputs": [],
      "source": [
        "compiler = EventPropCompiler(example_timesteps=int(np.ceil(EXAMPLE_TIME / DT)),\n",
        "                             losses=\"sparse_categorical_crossentropy\",\n",
        "                             optimiser=Adam(0.001), delay_optimiser=Adam(0.1), batch_size=BATCH_SIZE,\n",
        "                             softmax_temperature=0.5, ttfs_alpha=0.1, dt=DT, delay_learn_conns=[hidden])\n",
        "compiled_net = compiler.compile(network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATwobw4Mw2LG"
      },
      "source": [
        "## Training\n",
        "Now we will train the model for 10 epochs using our compiled network. To verify its performance we take 10% of the training data as a validation split and add an additional callback to checkpoint weights every epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EEQyoL-zcu-A",
        "outputId": "567a7e4e-bb10-4e69-c408-a1e759ac2ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "b543cd7d01834c8588e7c1ea16343380",
            "5c78b8de77a04052a3e653c6ba7ad23c",
            "808d36b47ae34cda998f1c3a8436809e",
            "a488b92243fe434fa63f6e343090537c",
            "4832bed76eb0470eb7d82787d8e565be",
            "97e10dec4ed94fefb231efdd0c130bd5",
            "08f65a6120ce4b2a96b76f2a086de889",
            "9034cc6e9c3c44a4adb8cdb1d7a16d45",
            "d0fa71cd2e224e83a67bc8648c7d2e40",
            "07f50e4bc56d4181966ad83a6b97a561",
            "5a011f9c67b841ae8f91ba829f6e5021"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b543cd7d01834c8588e7c1ea16343380"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e6947fe3bedb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Evaluate model on numpy dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_progress_bar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     compiled_net.train({input: spikes_train},\n\u001b[0m\u001b[1;32m      5\u001b[0m                        \u001b[0;34m{\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ml_genn/compilers/compiled_training_network.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, num_epochs, start_epoch, shuffle, metrics, callbacks, validation_callbacks, validation_split, validation_x, validation_y)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;31m# Loop through batches and train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_train_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 self._train_batch(batch_i, step_i, x_batch, y_batch,\n\u001b[0m\u001b[1;32m    186\u001b[0m                                   train_metrics, train_callback_list)\n\u001b[1;32m    187\u001b[0m                 \u001b[0mstep_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ml_genn/compilers/compiled_training_network.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, batch, step, x, y, metrics, callback_list)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Simulate timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# Get predictions from model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ml_genn/compilers/compiled_network.py\u001b[0m in \u001b[0;36mstep_time\u001b[0;34m(self, callback_list)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mcallback_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_timestep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ml_genn/utils/callback_list.py\u001b[0m in \u001b[0;36mon_timestep_end\u001b[0;34m(self, timestep)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_timestep_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_timestep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_timestep_end_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_timestep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with compiled_net:\n",
        "    # Evaluate model on numpy dataset\n",
        "    callbacks = [\"batch_progress_bar\", Checkpoint(serialiser)]\n",
        "    compiled_net.train({input: spikes_train},\n",
        "                       {output: labels_train},\n",
        "                       num_epochs=100, shuffle=True,\n",
        "                       callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate\n",
        "Load weights checkpointed from last epoch:"
      ],
      "metadata": {
        "id": "eQfD_7KP2gYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.load((14,), serialiser)"
      ],
      "metadata": {
        "id": "0k429OZXzqOC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an ``InferenceCompiler`` and compile network for inference:"
      ],
      "metadata": {
        "id": "nSwqjLCu2uAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiler = InferenceCompiler(evaluate_timesteps=20,\n",
        "                             reset_in_syn_between_batches=True,\n",
        "                             batch_size=BATCH_SIZE)\n",
        "compiled_net = compiler.compile(network)"
      ],
      "metadata": {
        "id": "ZITrB5w_0Fx4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode *test set* using the same log-latency encoding and evaluate it:"
      ],
      "metadata": {
        "id": "kW9KERs80y28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_spikes = linear_latency_encode_data(mnist.test_images(), 20.0)\n",
        "with compiled_net:\n",
        "    compiled_net.evaluate({input: test_spikes},\n",
        "                          {output: mnist.test_labels()})"
      ],
      "metadata": {
        "id": "6NQDJ1_o0LcY",
        "outputId": "3415e5ca-47f8-4bab-caad-dc28bf3ca93c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'linear_latency_encode_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b5c53b9247fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_spikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_latency_encode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcompiled_net\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     compiled_net.evaluate({input: test_spikes},\n\u001b[1;32m      4\u001b[0m                           {output: mnist.test_labels()})\n",
            "\u001b[0;31mNameError\u001b[0m: name 'linear_latency_encode_data' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tutorial_1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b543cd7d01834c8588e7c1ea16343380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c78b8de77a04052a3e653c6ba7ad23c",
              "IPY_MODEL_808d36b47ae34cda998f1c3a8436809e",
              "IPY_MODEL_a488b92243fe434fa63f6e343090537c"
            ],
            "layout": "IPY_MODEL_4832bed76eb0470eb7d82787d8e565be"
          }
        },
        "5c78b8de77a04052a3e653c6ba7ad23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97e10dec4ed94fefb231efdd0c130bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_08f65a6120ce4b2a96b76f2a086de889",
            "value": "Epoch 15:  33%"
          }
        },
        "808d36b47ae34cda998f1c3a8436809e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9034cc6e9c3c44a4adb8cdb1d7a16d45",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0fa71cd2e224e83a67bc8648c7d2e40",
            "value": 10
          }
        },
        "a488b92243fe434fa63f6e343090537c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f50e4bc56d4181966ad83a6b97a561",
            "placeholder": "​",
            "style": "IPY_MODEL_5a011f9c67b841ae8f91ba829f6e5021",
            "value": " 10/30 [00:00&lt;00:00, 24.61it/s, SparseCategoricalAccuracy: 0.7131]"
          }
        },
        "4832bed76eb0470eb7d82787d8e565be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e10dec4ed94fefb231efdd0c130bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f65a6120ce4b2a96b76f2a086de889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9034cc6e9c3c44a4adb8cdb1d7a16d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0fa71cd2e224e83a67bc8648c7d2e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07f50e4bc56d4181966ad83a6b97a561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a011f9c67b841ae8f91ba829f6e5021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}